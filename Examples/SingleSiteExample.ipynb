{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SINGLE SITE ANOMALY DETECTION AND CORRECTION\n",
    "This script performs anomaly detection and correction for multiple sensors at a single monitoring site.\n",
    "The script imports data, performs initial anomaly detection based on rules, uses models (ARIMA and 4 flavors of LSTM)\n",
    "and associated thresholds to detect anomalies, aggregates for overall anomaly detection, and performs correction\n",
    "based on ARIMA.\n",
    "\n",
    "Site: Logan River at Main Street\n",
    "\n",
    "Sensors: temperature, specific conductance, pH, dissolved oxygen\n",
    "\n",
    "Created: Amber Jones, March 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyHydroQC import anomaly_utilities\n",
    "from PyHydroQC import model_workflow\n",
    "from PyHydroQC import rules_detect\n",
    "from PyHydroQC import ARIMA_correct\n",
    "from PyHydroQC import modeling_utilities\n",
    "from PyHydroQC.model_workflow import ModelType"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameters may be specified in a parameters file or in this script\n",
    "from Examples.FB_parameters import site_params, LSTM_params, calib_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve data\n",
    "Creates an object with a data frame specific to each sensor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "site = 'MainStreet'\n",
    "sensors = ['temp', 'cond', 'ph', 'do']\n",
    "sensor_array = anomaly_utilities.get_data(sensors, filename='MS2018.csv', path='LRO_data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rules Based Anomaly Detection\n",
    "Performs checks for range and persistence. Min/max range and duration are defined in the parameters.\n",
    "Data outside a range or persisting longer than a duration are detected as anomalous, corrected by linear interpolation.\n",
    "The output is a column 'observed' of intermediate results that are used for subsequent modeling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "range_count = dict()\n",
    "persist_count = dict()\n",
    "rules_metrics = dict()\n",
    "for snsr in sensor_array:\n",
    "    sensor_array[snsr], range_count[snsr] = \\\n",
    "        rules_detect.range_check(sensor_array[snsr], site_params[site][snsr]['max_range'], site_params[site][snsr]['min_range'])\n",
    "    sensor_array[snsr], persist_count[snsr] = \\\n",
    "        rules_detect.persistence(sensor_array[snsr], site_params[site][snsr]['persist'], output_grp=True)\n",
    "    sensor_array[snsr] = rules_detect.interpolate(sensor_array[snsr])\n",
    "print('Rules based detection complete.\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect Calibration Events\n",
    "Calibration events are identified where persistence is within a certain window (e.g., after a sensor is returned to\n",
    "the water, it is 'stuck' and reports the same values for several time steps), the time of day within a certain window,\n",
    "and where these overlap for all sensors. When this occurs, an event is identified. Hours and durations are defined in\n",
    "the parameters. A subset of sensors are selected (1:4) because temperature is not calibrated. Calibration events \n",
    "detected here should be reviewed, compared to field records, and organized as input to the following step: drift correction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calib_sensors = sensors[1:4]\n",
    "input_array = dict()\n",
    "for snsr in calib_sensors:\n",
    "    input_array[snsr] = sensor_array[snsr]\n",
    "all_calib, all_calib_dates, df_all_calib, calib_dates_overlap = \\\n",
    "    rules_detect.calib_overlap(calib_sensors, input_array, calib_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform Linear Drift Correction\n",
    "Drift correction is performed when data are shifted due to calibration or cleaning of a sensor. To perform drift\n",
    "correction, the routine requires a start date, an end date, and a gap value to shift the data. This step requires\n",
    "some manual effort either after calibration events are detected as above or by reviewing field records and raw data.\n",
    "In this case, the inputs were determined from the scripts that technicians ran on these data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calib_dates = dict()\n",
    "for cal_snsr in calib_sensors:\n",
    "    calib_dates[cal_snsr] = \\\n",
    "        pd.read_csv('LRO_data/' + site + '_' + cal_snsr + '_calib_dates.csv', header=1, parse_dates=True, infer_datetime_format=True)\n",
    "    calib_dates[cal_snsr]['start'] = pd.to_datetime(calib_dates[cal_snsr]['start'])\n",
    "    calib_dates[cal_snsr]['end'] = pd.to_datetime(calib_dates[cal_snsr]['end'])\n",
    "    calib_dates[cal_snsr] = calib_dates[cal_snsr].loc[(calib_dates[cal_snsr]['start'] > min(sensor_array[cal_snsr].index)) &\n",
    "                                                      (calib_dates[cal_snsr]['start'] < max(sensor_array[cal_snsr].index))]\n",
    "\n",
    "    for i in range(min(calib_dates[cal_snsr].index), max(calib_dates[cal_snsr].index)):\n",
    "        result, sensor_array[cal_snsr]['observed'] = rules_detect.lin_drift_cor(\n",
    "                                                        sensor_array[cal_snsr]['observed'],\n",
    "                                                        calib_dates[cal_snsr]['start'][i],\n",
    "                                                        calib_dates[cal_snsr]['end'][i],\n",
    "                                                        calib_dates[cal_snsr]['gap'][i],\n",
    "                                                        replace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Based Anomaly Detection\n",
    "Generates 5 models. Each predict one step ahead using immediately previous data. Anomalies are detected by comparing\n",
    "model predictions to observations. Dynamic thresholds are based on model variability. Settings for ARIMA, LSTM, and\n",
    "threshold determination are set in the parameters. Metrics are output for each model type. Anomalies are\n",
    "aggregated so that any detection results in an anomaly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ARIMA Detection\n",
    "ARIMA models use a combination of past data in a linear form to predict the next value. These models are univariate.\n",
    "Each ARIMA model requires the parameters p, d, q, which can be defined automatically as shown here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_pdq = dict()\n",
    "for snsr in sensors:\n",
    "    all_pdq[snsr] = modeling_utilities.pdq(sensor_array[snsr]['observed'])\n",
    "    print(snsr + ' (p, d, q) = ' + str(all_pdq[snsr]))\n",
    "    site_params[site][snsr]['pdq'] = all_pdq[snsr]\n",
    "\n",
    "ARIMA = dict()\n",
    "for snsr in sensors:\n",
    "    ARIMA[snsr] = model_workflow.ARIMA_detect(sensor_array[snsr], snsr, site_params[site][snsr],\n",
    "                                              rules=False, plots=False, summary=False, compare=False)\n",
    "print('ARIMA detection complete.\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Detection\n",
    "LSTM models create a neural network that uses a sequence of past values to make a prediction. LSTM parameters are\n",
    "defined in the parameters file.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: univariate, MODEL: vanilla\n",
    "Uses a single sensor and several time steps prior to predict the next point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_univar = dict()\n",
    "for snsr in sensors:\n",
    "    LSTM_univar[snsr] = model_workflow.LSTM_detect_univar(\n",
    "            sensor_array[snsr], snsr, site_params[site][snsr], LSTM_params, model_type=ModelType.VANILLA,\n",
    "            rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: univariate,  MODEL: bidirectional\n",
    "Uses a single sensor and data before and after to predict a point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_univar_bidir = dict()\n",
    "for snsr in sensors:\n",
    "    LSTM_univar_bidir[snsr] = model_workflow.LSTM_detect_univar(\n",
    "            sensor_array[snsr], snsr, site_params[site][snsr], LSTM_params, model_type=ModelType.BIDIRECTIONAL,\n",
    "            rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: multivariate,  MODEL: vanilla\n",
    "Uses multiple sensors as inputs and outputs and data prior to predict the next point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_multivar = model_workflow.LSTM_detect_multivar(\n",
    "        sensor_array, sensors, site_params[site], LSTM_params, model_type=ModelType.VANILLA,\n",
    "        rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: multivariate,  MODEL: bidirectional\n",
    "Uses multiple sensors as inputs and outputs and data before and after to predict a point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_multivar_bidir = model_workflow.LSTM_detect_multivar(\n",
    "        sensor_array, sensors, site_params[site], LSTM_params, model_type=ModelType.BIDIRECTIONAL,\n",
    "        rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregate Detections for All Models\n",
    "Aggregates the results from all models and outputs metrics.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aggregate_results = dict()\n",
    "for snsr in sensors:\n",
    "    models = dict()\n",
    "    models['ARIMA'] = ARIMA[snsr].df\n",
    "    models['LSTM_univar'] = LSTM_univar[snsr].df_anomalies\n",
    "    models['LSTM_univar_bidir'] = LSTM_univar_bidir[snsr].df_anomalies\n",
    "    models['LSTM_multivar'] = LSTM_multivar.all_data[snsr]\n",
    "    models['LSTM_multivar_bidir'] = LSTM_multivar_bidir.all_data[snsr]\n",
    "    results_all = anomaly_utilities.aggregate_results(sensor_array[snsr], models, verbose=True, compare=True)\n",
    "    aggregate_results[snsr] = results_all\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correction\n",
    "Correction is performed using piecewise ARIMA- small models determined for each period of anomalous data, along with\n",
    "forecast and backcast, which consider data before and after a period of anomalous data and are merged together to ensure there is no dicontinuities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrections = dict()\n",
    "for snsr in sensors:\n",
    "    corrections[snsr] = ARIMA_correct.generate_corrections(aggregate_results[snsr], 'observed', 'detected_event')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#########################################\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}