{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SINGLE SITE ANOMALY DETECTION AND CORRECTION\n",
    "This script performs anomaly detection and correction for multiple sensors at a single monitoring site.\n",
    "The script imports data, performs initial anomaly detection based on rules, uses models (ARIMA and 4 flavors of LSTM)\n",
    "and associated thresholds to detect anomalies, aggregates for overall anomaly detection, and performs correction\n",
    "based on ARIMA.\n",
    "\n",
    "Site: Logan River at Main Street\n",
    "\n",
    "Sensors: temperature, specific conductance, pH, dissolved oxygen\n",
    "\n",
    "Created: Amber Jones, March 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyHydroQC import anomaly_utilities\n",
    "from PyHydroQC import model_workflow\n",
    "from PyHydroQC import rules_detect\n",
    "from PyHydroQC import ARIMA_correct\n",
    "from PyHydroQC import modeling_utilities\n",
    "from PyHydroQC.model_workflow import ModelType"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameters may be specified in a parameters file or in this script\n",
    "from Examples.FB_parameters import site_params, LSTM_params, calib_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve data\n",
    "Creates an object with a data frame specific to each sensor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "site = 'MainStreet'\n",
    "sensors = ['temp', 'cond', 'ph', 'do']\n",
    "sensor_array = anomaly_utilities.get_data(sensors=sensors, filename='MS2018.csv', path='LRO_data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rules Based Anomaly Detection\n",
    "Performs checks for range and persistence. Min/max range and duration are defined in the parameters.\n",
    "Data outside a range or persisting longer than a duration are detected as anomalous, corrected by linear interpolation.\n",
    "The output is a column 'observed' of intermediate results that are used for subsequent modeling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "range_count = dict()\n",
    "persist_count = dict()\n",
    "rules_metrics = dict()\n",
    "for snsr in sensor_array:\n",
    "    sensor_array[snsr], range_count[snsr] = rules_detect.range_check(\n",
    "        df=sensor_array[snsr], maximum=site_params[site][snsr]['max_range'], minimum=site_params[site][snsr]['min_range'])\n",
    "    sensor_array[snsr], persist_count[snsr] = rules_detect.persistence(\n",
    "        df=sensor_array[snsr], length=site_params[site][snsr]['persist'], output_grp=True)\n",
    "    sensor_array[snsr] = rules_detect.interpolate(df=sensor_array[snsr])\n",
    "print('Rules based detection complete.\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect Calibration Events\n",
    "Calibration events are identified where persistence is within a certain window (e.g., after a sensor is returned to\n",
    "the water, it is 'stuck' and reports the same values for several time steps), the time of day within a certain window,\n",
    "and where these overlap for all sensors. When this occurs, an event is identified. Hours and durations are defined in\n",
    "the parameters. A subset of sensors are selected (1:4) because temperature is not calibrated. Calibration events \n",
    "detected here should be reviewed, compared to field records, and organized as input to the following step: \n",
    "drift correction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calib_sensors = sensors[1:4]\n",
    "input_array = dict()\n",
    "for snsr in calib_sensors:\n",
    "    input_array[snsr] = sensor_array[snsr]\n",
    "all_calib, all_calib_dates, df_all_calib, calib_dates_overlap = rules_detect.calib_overlap(\n",
    "    sensor_names=calib_sensors, input_array=input_array, calib_params=calib_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform Linear Drift Correction\n",
    "Drift correction is a correction used when data are shifted due to calibration or cleaning of a sensor. To perform drift\n",
    "correction, the routine requires a start date, an end date, and a gap value to shift the data for each event. This step \n",
    "requires some manual effort either after calibration events are detected as above or by reviewing field records and raw \n",
    "data. In this case, the inputs were determined from the scripts that technicians previously ran on these data and are \n",
    "stored in a spreadsheet with columns for start date, end date, and gap value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calib_dates = dict()\n",
    "for cal_snsr in calib_sensors:\n",
    "    calib_dates[cal_snsr] = pd.read_csv(\n",
    "        'LRO_data/' + site + '_' + cal_snsr + '_calib_dates.csv', header=1, parse_dates=True, infer_datetime_format=True)\n",
    "    calib_dates[cal_snsr]['start'] = pd.to_datetime(calib_dates[cal_snsr]['start'])\n",
    "    calib_dates[cal_snsr]['end'] = pd.to_datetime(calib_dates[cal_snsr]['end'])\n",
    "    calib_dates[cal_snsr] = calib_dates[cal_snsr].loc[(calib_dates[cal_snsr]['start'] > min(sensor_array[cal_snsr].index)) &\n",
    "                                                      (calib_dates[cal_snsr]['start'] < max(sensor_array[cal_snsr].index))]\n",
    "\n",
    "    for i in range(min(calib_dates[cal_snsr].index), max(calib_dates[cal_snsr].index)):\n",
    "        result, sensor_array[cal_snsr]['observed'] = rules_detect.lin_drift_cor(\n",
    "                                                        observed=sensor_array[cal_snsr]['observed'],\n",
    "                                                        start=calib_dates[cal_snsr]['start'][i],\n",
    "                                                        end=calib_dates[cal_snsr]['end'][i],\n",
    "                                                        gap=calib_dates[cal_snsr]['gap'][i],\n",
    "                                                        replace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Based Anomaly Detection\n",
    "Generates 5 models. Each model predicts one step ahead using immediately adjacent data. Anomalies are detected by \n",
    "comparing the model residual (predictions - observations) to a threshold. Dynamic thresholds are based on model \n",
    "variability. Settings for ARIMA, LSTM, and threshold determination are in the parameters. Results from all models are \n",
    "aggregated so that a detection by any model results in an anomaly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ARIMA Detection\n",
    "ARIMA models use a combination of past data in a linear form to predict the next value. These models are univariate.\n",
    "Each ARIMA model requires the parameters p, d, q, which can be defined automatically as shown here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_pdq = dict()\n",
    "for snsr in sensors:\n",
    "    all_pdq[snsr] = modeling_utilities.pdq(data=sensor_array[snsr]['observed'])\n",
    "    print(snsr + ' (p, d, q) = ' + str(all_pdq[snsr]))\n",
    "    site_params[site][snsr]['pdq'] = all_pdq[snsr]\n",
    "\n",
    "ARIMA = dict()\n",
    "for snsr in sensors:\n",
    "    ARIMA[snsr] = model_workflow.ARIMA_detect(df=sensor_array[snsr], sensor=snsr, params=site_params[site][snsr],\n",
    "                                              rules=False, plots=False, summary=False, compare=False)\n",
    "print('ARIMA detection complete.\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Detection\n",
    "LSTM models create a neural network that uses a sequence of values to make a prediction. Settings and hyperparameters \n",
    "are defined in the parameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: univariate, MODEL: vanilla\n",
    "Uses a single sensor and data prior to predict the next point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_univar = dict()\n",
    "for snsr in sensors:\n",
    "    LSTM_univar[snsr] = model_workflow.LSTM_detect_univar(\n",
    "            df=sensor_array[snsr], sensor=snsr, params=site_params[site][snsr], LSTM_params=LSTM_params, model_type=ModelType.VANILLA,\n",
    "            rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: univariate,  MODEL: bidirectional\n",
    "Uses a single sensor and data before and after to predict a point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_univar_bidir = dict()\n",
    "for snsr in sensors:\n",
    "    LSTM_univar_bidir[snsr] = model_workflow.LSTM_detect_univar(\n",
    "            df=sensor_array[snsr], sensor=snsr, params=site_params[site][snsr], LSTM_params=LSTM_params, model_type=ModelType.BIDIRECTIONAL,\n",
    "            rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: multivariate,  MODEL: vanilla\n",
    "Uses multiple sensors as inputs and outputs and data prior to predict the next point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_multivar = model_workflow.LSTM_detect_multivar(\n",
    "        sensor_array=sensor_array, sensors=sensors, params=site_params[site], LSTM_params=LSTM_params, model_type=ModelType.VANILLA,\n",
    "        rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DATA: multivariate,  MODEL: bidirectional\n",
    "Uses multiple sensors as inputs and outputs and data before and after to predict a point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTM_multivar_bidir = model_workflow.LSTM_detect_multivar(\n",
    "        sensor_array=sensor_array, sensors=sensors, params=site_params[site], LSTM_params=LSTM_params, model_type=ModelType.BIDIRECTIONAL,\n",
    "        rules=False, plots=False, summary=False, compare=False, model_output=False, model_save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregate Detections for All Models\n",
    "Aggregates the results from all models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aggregate_results = dict()\n",
    "for snsr in sensors:\n",
    "    models = dict()\n",
    "    models['ARIMA'] = ARIMA[snsr].df\n",
    "    models['LSTM_univar'] = LSTM_univar[snsr].df_anomalies\n",
    "    models['LSTM_univar_bidir'] = LSTM_univar_bidir[snsr].df_anomalies\n",
    "    models['LSTM_multivar'] = LSTM_multivar.all_data[snsr]\n",
    "    models['LSTM_multivar_bidir'] = LSTM_multivar_bidir.all_data[snsr]\n",
    "    results_all = anomaly_utilities.aggregate_results(\n",
    "        df=sensor_array[snsr], models=models, verbose=True, compare=True)\n",
    "    aggregate_results[snsr] = results_all\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correction\n",
    "Correction is performed using piecewise ARIMA- small models determined for each period of anomalous data, along with\n",
    "forecast and backcast, which consider data before and after a period of anomalous data and are merged together to \n",
    "ensure there are no discontinuities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrections = dict()\n",
    "corrections = dict()\n",
    "for snsr in sensors:\n",
    "    corrections[snsr] = ARIMA_correct.generate_corrections(\n",
    "        df=aggregate_results[snsr], observed='observed', anomalies='detected_event')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#########################################\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}